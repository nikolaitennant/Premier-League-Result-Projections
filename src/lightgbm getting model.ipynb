{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459dc989",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26afbdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[ OK ]\u001b[0m Python version is 3.10.5\n",
      "\n",
      "\u001b[42m[ OK ]\u001b[0m numpy version 1.22.4 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m matplotlib version 3.5.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m sklearn version 1.1.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pandas version 1.4.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m xgboost version 1.5.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m shap version 0.40.0 is installed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "import warnings;   warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.10 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.10\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.10\"):\n",
    "    print(FAIL, \"Python version 3.10 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"1.22.4\", 'matplotlib': \"3.5.2\",'sklearn': \"1.1.1\", \n",
    "                'pandas': \"1.4.2\",'xgboost': \"1.5.1\", 'shap': \"0.40.0\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea27788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from itertools import accumulate\n",
    "import six\n",
    "\n",
    "\n",
    "final_dataset = pd.read_csv('../results/Tables/final_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cef35c",
   "metadata": {},
   "source": [
    "# Lagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2973782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of data with 7 lags\n",
    "\n",
    "#features to lag\n",
    "Referee = final_dataset['Referee']\n",
    "Result = final_dataset['Result']\n",
    "B365H = final_dataset['B365H']\n",
    "B365D = final_dataset['B365D']\n",
    "B365A = final_dataset['B365A']\n",
    "HICT = final_dataset['HICT']\n",
    "AICT = final_dataset['AICT']\n",
    "DifICT = final_dataset['DifICT']\n",
    "\n",
    "y7 = final_dataset['Result']\n",
    "X7 = pd.concat([Referee, Result, \n",
    "                \n",
    "                \n",
    "B365H.shift(7),B365H.shift(6),B365H.shift(5),B365H.shift(4),B365H.shift(3),B365H.shift(2), B365H.shift(1),B365H, \n",
    "                \n",
    "B365D.shift(7),B365D.shift(6), B365D.shift(5),B365D.shift(4),B365D.shift(3), B365D.shift(2),B365D.shift(1),B365D, \n",
    "\n",
    "B365A.shift(7),B365A.shift(6), B365A.shift(5),B365A.shift(4), B365A.shift(3),B365A.shift(2),B365A.shift(1),B365A, \n",
    "\n",
    "HICT.shift(7),HICT.shift(6), HICT.shift(5),HICT.shift(4),HICT.shift(3),HICT.shift(2),HICT.shift(1),HICT, \n",
    "               \n",
    "AICT.shift(7),AICT.shift(6), AICT.shift(5),AICT.shift(4),AICT.shift(3),AICT.shift(2),AICT.shift(1),AICT, \n",
    "               \n",
    "DifICT.shift(7),DifICT.shift(6), DifICT.shift(5),DifICT.shift(4),DifICT.shift(3),DifICT.shift(2),DifICT.shift(1),DifICT],\n",
    "              \n",
    "               axis=1)\n",
    "\n",
    "X7.columns = ['Referee', 'Result',\n",
    "              \n",
    "              'B365H lag 7 matches','B365H lag 6 matches','B365H lag 5 matches', 'B365H lag 4 matches', \n",
    "              'B365H lag 3 matches','B365H lag 2 matches', 'B365H lag 1 match', 'B365H most recent match',\n",
    "             \n",
    "              'B365D lag 7 matches', 'B365D lag 6 matches', 'B365D lag 5 matches', 'B365D lag 4 matches', \n",
    "              'B365D lag 3 matches', 'B365D lag 2 matches', 'B365D lag 1 match', 'B365D most recent match',\n",
    "             \n",
    "              'B365A lag 7 matches', 'B365A lag 6 matches', 'B365A lag 5 matches', 'B365A lag 4 matches', \n",
    "              'B365A lag 3 matches','B365A lag 2 matches', 'B365A lag 1 match', 'B365A most recent match',       \n",
    "             \n",
    "              'HICT lag 7 matches', 'HICT lag 6 matches', 'HICT lag 5 matches', 'HICT lag 4 matches', \n",
    "              'HICT lag 3 matches','HICT lag 2 matches', 'HICT lag 1 match', 'HICT most recent match',       \n",
    "             \n",
    "              'AICT lag 7 matches', 'AICT lag 6 matches', 'AICT lag 5 matches', 'AICT lag 4 matches', \n",
    "              'AICT lag 3 matches','AICT lag 2 matches', 'AICT lag 1 match', 'AICT most recent match',\n",
    "              \n",
    "              'DifICT lag 7 matches', 'DifICT lag 6 matches', 'DifICT lag 5 matches', 'DifICT lag 4 matches', \n",
    "              'DifICT lag 3 matches','DifICT lag 2 matches', 'DifICT lag 1 match', 'DifICT most recent match'] \n",
    "\n",
    "# print(X7.tail(10))\n",
    "# print(y7.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d94a2e",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf71cf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Referee</th>\n",
       "      <th>Result</th>\n",
       "      <th>B365H lag 7 matches</th>\n",
       "      <th>B365H lag 6 matches</th>\n",
       "      <th>B365H lag 5 matches</th>\n",
       "      <th>B365H lag 4 matches</th>\n",
       "      <th>B365H lag 3 matches</th>\n",
       "      <th>B365H lag 2 matches</th>\n",
       "      <th>B365H lag 1 match</th>\n",
       "      <th>B365H most recent match</th>\n",
       "      <th>...</th>\n",
       "      <th>AICT lag 1 match</th>\n",
       "      <th>AICT most recent match</th>\n",
       "      <th>DifICT lag 7 matches</th>\n",
       "      <th>DifICT lag 6 matches</th>\n",
       "      <th>DifICT lag 5 matches</th>\n",
       "      <th>DifICT lag 4 matches</th>\n",
       "      <th>DifICT lag 3 matches</th>\n",
       "      <th>DifICT lag 2 matches</th>\n",
       "      <th>DifICT lag 1 match</th>\n",
       "      <th>DifICT most recent match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Marriner</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.66</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M Atkinson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.66</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Taylor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.66</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5.50</td>\n",
       "      <td>...</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>-300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M Atkinson</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.66</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5.50</td>\n",
       "      <td>2.55</td>\n",
       "      <td>...</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G Scott</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.66</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5.50</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.08</td>\n",
       "      <td>...</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>-300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>M Oliver</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>8303.1</td>\n",
       "      <td>8698.8</td>\n",
       "      <td>404.8</td>\n",
       "      <td>314.8</td>\n",
       "      <td>441.9</td>\n",
       "      <td>415.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>-576.1</td>\n",
       "      <td>-526.5</td>\n",
       "      <td>-375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>P Tierney</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.05</td>\n",
       "      <td>...</td>\n",
       "      <td>8698.8</td>\n",
       "      <td>7765.2</td>\n",
       "      <td>314.8</td>\n",
       "      <td>441.9</td>\n",
       "      <td>415.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>-576.1</td>\n",
       "      <td>-526.5</td>\n",
       "      <td>-375.0</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>C Kavanagh</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.72</td>\n",
       "      <td>...</td>\n",
       "      <td>7765.2</td>\n",
       "      <td>7793.7</td>\n",
       "      <td>441.9</td>\n",
       "      <td>415.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>-576.1</td>\n",
       "      <td>-526.5</td>\n",
       "      <td>-375.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>382.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>D Coote</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.72</td>\n",
       "      <td>3.60</td>\n",
       "      <td>...</td>\n",
       "      <td>7793.7</td>\n",
       "      <td>8402.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>-576.1</td>\n",
       "      <td>-526.5</td>\n",
       "      <td>-375.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>382.5</td>\n",
       "      <td>-400.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>A Taylor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.72</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.30</td>\n",
       "      <td>...</td>\n",
       "      <td>8402.0</td>\n",
       "      <td>8081.8</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>-576.1</td>\n",
       "      <td>-526.5</td>\n",
       "      <td>-375.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>382.5</td>\n",
       "      <td>-400.8</td>\n",
       "      <td>-285.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Referee  Result  B365H lag 7 matches  B365H lag 6 matches  \\\n",
       "0    A Marriner     0.0                 4.00                 1.90   \n",
       "1    M Atkinson     0.0                 1.90                 3.10   \n",
       "2      A Taylor     2.0                 3.10                 1.25   \n",
       "3    M Atkinson     1.0                 1.25                 3.10   \n",
       "4       G Scott     2.0                 3.10                 1.53   \n",
       "..          ...     ...                  ...                  ...   \n",
       "445    M Oliver     2.0                 1.33                 1.75   \n",
       "446   P Tierney     2.0                 1.75                 1.40   \n",
       "447  C Kavanagh     2.0                 1.40                 1.83   \n",
       "448     D Coote     0.0                 1.83                 1.11   \n",
       "449    A Taylor     1.0                 1.11                 3.60   \n",
       "\n",
       "     B365H lag 5 matches  B365H lag 4 matches  B365H lag 3 matches  \\\n",
       "0                   3.10                 1.25                 3.10   \n",
       "1                   1.25                 3.10                 1.53   \n",
       "2                   3.10                 1.53                 1.66   \n",
       "3                   1.53                 1.66                 9.00   \n",
       "4                   1.66                 9.00                 3.20   \n",
       "..                   ...                  ...                  ...   \n",
       "445                 1.40                 1.83                 1.11   \n",
       "446                 1.83                 1.11                 3.60   \n",
       "447                 1.11                 3.60                 2.80   \n",
       "448                 3.60                 2.80                 2.50   \n",
       "449                 2.80                 2.50                 2.05   \n",
       "\n",
       "     B365H lag 2 matches  B365H lag 1 match  B365H most recent match  ...  \\\n",
       "0                   1.53               1.66                     9.00  ...   \n",
       "1                   1.66               9.00                     3.20  ...   \n",
       "2                   9.00               3.20                     5.50  ...   \n",
       "3                   3.20               5.50                     2.55  ...   \n",
       "4                   5.50               2.55                     1.08  ...   \n",
       "..                   ...                ...                      ...  ...   \n",
       "445                 3.60               2.80                     2.50  ...   \n",
       "446                 2.80               2.50                     2.05  ...   \n",
       "447                 2.50               2.05                     1.72  ...   \n",
       "448                 2.05               1.72                     3.60  ...   \n",
       "449                 1.72               3.60                     3.30  ...   \n",
       "\n",
       "     AICT lag 1 match  AICT most recent match  DifICT lag 7 matches  \\\n",
       "0              7800.0                  8400.0                -600.0   \n",
       "1              8400.0                  7900.0                 300.0   \n",
       "2              7900.0                  8500.0                   0.0   \n",
       "3              8500.0                  7300.0                 700.0   \n",
       "4              7300.0                  7400.0                -300.0   \n",
       "..                ...                     ...                   ...   \n",
       "445            8303.1                  8698.8                 404.8   \n",
       "446            8698.8                  7765.2                 314.8   \n",
       "447            7765.2                  7793.7                 441.9   \n",
       "448            7793.7                  8402.0                 415.0   \n",
       "449            8402.0                  8081.8                1194.0   \n",
       "\n",
       "     DifICT lag 6 matches  DifICT lag 5 matches  DifICT lag 4 matches  \\\n",
       "0                   300.0                   0.0                 700.0   \n",
       "1                     0.0                 700.0                -300.0   \n",
       "2                   700.0                -300.0                 800.0   \n",
       "3                  -300.0                 800.0                 200.0   \n",
       "4                   800.0                 200.0               -1000.0   \n",
       "..                    ...                   ...                   ...   \n",
       "445                 314.8                 441.9                 415.0   \n",
       "446                 441.9                 415.0                1194.0   \n",
       "447                 415.0                1194.0                -576.1   \n",
       "448                1194.0                -576.1                -526.5   \n",
       "449                -576.1                -526.5                -375.0   \n",
       "\n",
       "     DifICT lag 3 matches  DifICT lag 2 matches  DifICT lag 1 match  \\\n",
       "0                  -300.0                 800.0               200.0   \n",
       "1                   800.0                 200.0             -1000.0   \n",
       "2                   200.0               -1000.0              -300.0   \n",
       "3                 -1000.0                -300.0              -300.0   \n",
       "4                  -300.0                -300.0               300.0   \n",
       "..                    ...                   ...                 ...   \n",
       "445                1194.0                -576.1              -526.5   \n",
       "446                -576.1                -526.5              -375.0   \n",
       "447                -526.5                -375.0                29.9   \n",
       "448                -375.0                  29.9               382.5   \n",
       "449                  29.9                 382.5              -400.8   \n",
       "\n",
       "     DifICT most recent match  \n",
       "0                     -1000.0  \n",
       "1                      -300.0  \n",
       "2                      -300.0  \n",
       "3                       300.0  \n",
       "4                      1100.0  \n",
       "..                        ...  \n",
       "445                    -375.0  \n",
       "446                      29.9  \n",
       "447                     382.5  \n",
       "448                    -400.8  \n",
       "449                    -285.7  \n",
       "\n",
       "[450 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect which encoder to use on each feature\n",
    "onehot_ftrs_7 = ['Referee']\n",
    "minmax_ftrs_7 = ['HICT lag 7 matches', 'HICT lag 6 matches','HICT lag 5 matches', 'HICT lag 4 matches', \n",
    "                 'HICT lag 3 matches', 'HICT lag 2 matches', 'HICT lag 1 match', 'HICT most recent match',       \n",
    "            \n",
    "                 'AICT lag 7 matches', 'AICT lag 6 matches','AICT lag 5 matches', 'AICT lag 4 matches', \n",
    "                 'AICT lag 3 matches','AICT lag 2 matches', 'AICT lag 1 match', 'AICT most recent match']\n",
    "               \n",
    "std_ftrs_7 = ['B365H lag 7 matches', 'B365H lag 6 matches', 'B365H lag 5 matches', 'B365H lag 4 matches', \n",
    "              'B365H lag 3 matches','B365H lag 2 matches', 'B365H lag 1 match', 'B365H most recent match',\n",
    "              \n",
    "              'B365D lag 7 matches', 'B365D lag 6 matches', 'B365D lag 5 matches', 'B365D lag 4 matches', \n",
    "              'B365D lag 3 matches', 'B365D lag 2 matches', 'B365D lag 1 match', 'B365D most recent match',\n",
    "              \n",
    "              'B365A lag 7 matches', 'B365A lag 6 matches', 'B365A lag 5 matches', 'B365A lag 4 matches', \n",
    "              'B365A lag 3 matches', 'B365A lag 2 matches', 'B365A lag 1 match', 'B365A most recent match',       \n",
    "              \n",
    "              'DifICT lag 7 matches', 'DifICT lag 6 matches','DifICT lag 5 matches', 'DifICT lag 4 matches', \n",
    "              'DifICT lag 3 matches', 'DifICT lag 2 matches', 'DifICT lag 1 match', 'DifICT most recent match']\n",
    "    \n",
    "# collect all the encoders\n",
    "preprocessor_7 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs_7),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs_7),\n",
    "        ('std', StandardScaler(), std_ftrs_7)])\n",
    "\n",
    "#create dataframe for splitting\n",
    "X7_lagged = X7.iloc[7:].reset_index(drop = True)\n",
    "#X7_lagged = X7_lagged.drop(['Result'], axis = 1)\n",
    "y7_lagged = y7.iloc[7:].reset_index(drop = True)\n",
    "X7_lagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7db86",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "171f279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "import statistics as stat\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as LGB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8964c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Pipeline for Lightgbm\n",
    "def MLpipe_RS_lgb(X, y, model, n_splits, preprocessor, scoring, refit, lags):\n",
    "    '''ML Pipeline for LightGBM. Takes in a X df, the target variable, the number of splits for \n",
    "    timesplit, a preprocessor, the scoring method, the refit method, and lags of dataset\n",
    "    Returns: best models, best test scores, confusion matrices, the lag used, and baseline scores of each split'''\n",
    "    \n",
    "    X_other = X.iloc[:250]\n",
    "    X_test = X.iloc[250:]\n",
    "    y_other = y.iloc[:250]\n",
    "    y_test = y.iloc[250:]\n",
    "    print(y_test.value_counts())\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits)\n",
    "    \n",
    "    #create empty Variables\n",
    "    best_models = []\n",
    "    best_scores = []\n",
    "    cm = []\n",
    "    random_states = [1, 10, 42, 60, 90]\n",
    "    \n",
    "    #loop through random states\n",
    "    for i in random_states:\n",
    "        \n",
    "        #set parameter grid\n",
    "        param_grid ={\n",
    "            'ml__n_estimators': [5],\n",
    "            'ml__num_leaves': [3,6,8,31], \n",
    "            'ml__max_depth': [40],\n",
    "            'ml__colsample_bytree': [0.99],\n",
    "            'ml__min_child_samples': [5,20,25,50], \n",
    "            'ml__min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "            'ml__random_state': [i]}\n",
    "             \n",
    "        #create pipeline\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor), ('ml', model)])\n",
    "\n",
    "        #use gridsearchcv to tune\n",
    "        gsearch = GridSearchCV(pipe, cv=tscv.split(X_other), param_grid= param_grid, scoring = scoring, refit = refit)\n",
    "        \n",
    "        #fit model\n",
    "        gsearch.fit(X_other, y_other) \n",
    "\n",
    "        #save important info\n",
    "        best_models.append(gsearch)\n",
    "        best_param = gsearch.best_params_\n",
    "        #feature_names = best_model[:-1].get_feature_names_out()\n",
    "        \n",
    "        #predict and save accuracy scores/best models\n",
    "        y_pred = best_models[-1].predict(X_test)\n",
    "        test_score = accuracy_score(y_test,y_pred)\n",
    "        best_scores.append(test_score)\n",
    "        cm.append(confusion_matrix(y_test,y_pred))\n",
    "        print('---------------------------------------------------------------------------------------------------')\n",
    "\n",
    "        print('\\nBest Parameters\\n')\n",
    "        print(best_param)\n",
    "\n",
    "        print('\\nConfusion Matrix\\n')\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "        print('Accuracy: {:.2f}\\n'.format(test_score))\n",
    "\n",
    "        print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "        print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "        print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "        print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "        print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "        print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "        print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "        print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "        print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "        print('\\nClassification Report\\n')\n",
    "        print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1', 'Class 2']))\n",
    "        \n",
    "    #create average scores\n",
    "    score = stat.mean(best_scores)\n",
    "    score = score.round(3)\n",
    "    std = stat.stdev(best_scores)\n",
    "    std = round(std,3)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print(f'Averaged Accuracy score: {score:.2f}%, ' f'std: {std:.2f}%, ' f'# of Lags: {lags:.0f}')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    return best_models, best_scores, cm, lags\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2d697b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Pipeline for Lightgbm\n",
    "def MLpipe_RS_lgb(X, y, model, n_splits, preprocessor, scoring, refit, lags):\n",
    "    '''ML Pipeline for LightGBM. Takes in a X df, the target variable, the number of splits for \n",
    "    timesplit, a preprocessor, the scoring method, the refit method, and lags of dataset\n",
    "    Returns: best models, best test scores, confusion matrices, the lag used, and baseline scores of each split'''\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits)\n",
    "    \n",
    "    #create empty Variables\n",
    "    best_models = []\n",
    "    best_scores = []\n",
    "    cm = []\n",
    "    random_states = [1, 10, 42, 60, 90]\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        #loop through random states\n",
    "        for i in random_states:\n",
    "\n",
    "            #set parameter grid\n",
    "            param_grid ={\n",
    "                'ml__n_estimators': [5],\n",
    "                'ml__num_leaves': [3,6,8,31], \n",
    "                'ml__max_depth': [40],\n",
    "                'ml__colsample_bytree': [0.99],\n",
    "                'ml__min_child_samples': [5,20,25,50], \n",
    "                'ml__min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "                'ml__random_state': [i]}\n",
    "\n",
    "            #create pipeline\n",
    "            pipe = Pipeline(steps=[('preprocessor', preprocessor), ('ml', model)])\n",
    "\n",
    "            #use gridsearchcv to tune\n",
    "            gsearch = GridSearchCV(pipe, cv=tscv.split(X_train), param_grid= param_grid, scoring = scoring, refit = refit)\n",
    "\n",
    "            #fit model\n",
    "            gsearch.fit(X_train, y_train) \n",
    "\n",
    "            #save important info\n",
    "            best_models.append(gsearch)\n",
    "            best_param = gsearch.best_params_\n",
    "            #feature_names = best_model[:-1].get_feature_names_out()\n",
    "\n",
    "            #predict and save accuracy scores/best models\n",
    "            y_pred = best_models[-1].predict(X_test)\n",
    "            test_score = accuracy_score(y_test,y_pred)\n",
    "            best_scores.append(test_score)\n",
    "            cm.append(confusion_matrix(y_test,y_pred))\n",
    "            print('---------------------------------------------------------------------------------------------------')\n",
    "\n",
    "            print('\\nBest Parameters\\n')\n",
    "            print(best_param)\n",
    "\n",
    "            print('\\nConfusion Matrix\\n')\n",
    "            print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "            print('Accuracy: {:.2f}\\n'.format(test_score))\n",
    "\n",
    "            print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "            print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "            print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "            print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "            print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "            print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "            print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "            print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "            print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "            print('\\nClassification Report\\n')\n",
    "            print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1', 'Class 2']))\n",
    "        \n",
    "    #create average scores\n",
    "    score = stat.mean(best_scores)\n",
    "    score = score.round(3)\n",
    "    std = stat.stdev(best_scores)\n",
    "    std = round(std,3)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print(f'Averaged Accuracy score: {score:.2f}%, ' f'std: {std:.2f}%, ' f'# of Lags: {lags:.0f}')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    return best_models, best_scores, cm, lags\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12856864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 1}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[34  0 25]\n",
      " [10  2 18]\n",
      " [ 6  0 55]]\n",
      "Accuracy: 0.61\n",
      "\n",
      "Micro Precision: 0.61\n",
      "Micro Recall: 0.61\n",
      "Micro F1-score: 0.61\n",
      "\n",
      "Macro Precision: 0.75\n",
      "Macro Recall: 0.51\n",
      "Macro F1-score: 0.48\n",
      "\n",
      "Weighted Precision: 0.70\n",
      "Weighted Recall: 0.61\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.68      0.58      0.62        59\n",
      "     Class 1       1.00      0.07      0.12        30\n",
      "     Class 2       0.56      0.90      0.69        61\n",
      "\n",
      "    accuracy                           0.61       150\n",
      "   macro avg       0.75      0.51      0.48       150\n",
      "weighted avg       0.70      0.61      0.55       150\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 10}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[34  0 25]\n",
      " [10  2 18]\n",
      " [ 6  0 55]]\n",
      "Accuracy: 0.61\n",
      "\n",
      "Micro Precision: 0.61\n",
      "Micro Recall: 0.61\n",
      "Micro F1-score: 0.61\n",
      "\n",
      "Macro Precision: 0.75\n",
      "Macro Recall: 0.51\n",
      "Macro F1-score: 0.48\n",
      "\n",
      "Weighted Precision: 0.70\n",
      "Weighted Recall: 0.61\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.68      0.58      0.62        59\n",
      "     Class 1       1.00      0.07      0.12        30\n",
      "     Class 2       0.56      0.90      0.69        61\n",
      "\n",
      "    accuracy                           0.61       150\n",
      "   macro avg       0.75      0.51      0.48       150\n",
      "weighted avg       0.70      0.61      0.55       150\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 42}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[34  0 25]\n",
      " [10  2 18]\n",
      " [ 6  0 55]]\n",
      "Accuracy: 0.61\n",
      "\n",
      "Micro Precision: 0.61\n",
      "Micro Recall: 0.61\n",
      "Micro F1-score: 0.61\n",
      "\n",
      "Macro Precision: 0.75\n",
      "Macro Recall: 0.51\n",
      "Macro F1-score: 0.48\n",
      "\n",
      "Weighted Precision: 0.70\n",
      "Weighted Recall: 0.61\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.68      0.58      0.62        59\n",
      "     Class 1       1.00      0.07      0.12        30\n",
      "     Class 2       0.56      0.90      0.69        61\n",
      "\n",
      "    accuracy                           0.61       150\n",
      "   macro avg       0.75      0.51      0.48       150\n",
      "weighted avg       0.70      0.61      0.55       150\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 60}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[34  0 25]\n",
      " [10  2 18]\n",
      " [ 6  0 55]]\n",
      "Accuracy: 0.61\n",
      "\n",
      "Micro Precision: 0.61\n",
      "Micro Recall: 0.61\n",
      "Micro F1-score: 0.61\n",
      "\n",
      "Macro Precision: 0.75\n",
      "Macro Recall: 0.51\n",
      "Macro F1-score: 0.48\n",
      "\n",
      "Weighted Precision: 0.70\n",
      "Weighted Recall: 0.61\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.68      0.58      0.62        59\n",
      "     Class 1       1.00      0.07      0.12        30\n",
      "     Class 2       0.56      0.90      0.69        61\n",
      "\n",
      "    accuracy                           0.61       150\n",
      "   macro avg       0.75      0.51      0.48       150\n",
      "weighted avg       0.70      0.61      0.55       150\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 90}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[34  0 25]\n",
      " [10  2 18]\n",
      " [ 6  0 55]]\n",
      "Accuracy: 0.61\n",
      "\n",
      "Micro Precision: 0.61\n",
      "Micro Recall: 0.61\n",
      "Micro F1-score: 0.61\n",
      "\n",
      "Macro Precision: 0.75\n",
      "Macro Recall: 0.51\n",
      "Macro F1-score: 0.48\n",
      "\n",
      "Weighted Precision: 0.70\n",
      "Weighted Recall: 0.61\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.68      0.58      0.62        59\n",
      "     Class 1       1.00      0.07      0.12        30\n",
      "     Class 2       0.56      0.90      0.69        61\n",
      "\n",
      "    accuracy                           0.61       150\n",
      "   macro avg       0.75      0.51      0.48       150\n",
      "weighted avg       0.70      0.61      0.55       150\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 1}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[27  0 12]\n",
      " [14  1 25]\n",
      " [17  0 54]]\n",
      "Accuracy: 0.55\n",
      "\n",
      "Micro Precision: 0.55\n",
      "Micro Recall: 0.55\n",
      "Micro F1-score: 0.55\n",
      "\n",
      "Macro Precision: 0.69\n",
      "Macro Recall: 0.49\n",
      "Macro F1-score: 0.42\n",
      "\n",
      "Weighted Precision: 0.67\n",
      "Weighted Recall: 0.55\n",
      "Weighted F1-score: 0.47\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.69      0.56        39\n",
      "     Class 1       1.00      0.03      0.05        40\n",
      "     Class 2       0.59      0.76      0.67        71\n",
      "\n",
      "    accuracy                           0.55       150\n",
      "   macro avg       0.69      0.49      0.42       150\n",
      "weighted avg       0.67      0.55      0.47       150\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 10}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[27  0 12]\n",
      " [14  1 25]\n",
      " [17  0 54]]\n",
      "Accuracy: 0.55\n",
      "\n",
      "Micro Precision: 0.55\n",
      "Micro Recall: 0.55\n",
      "Micro F1-score: 0.55\n",
      "\n",
      "Macro Precision: 0.69\n",
      "Macro Recall: 0.49\n",
      "Macro F1-score: 0.42\n",
      "\n",
      "Weighted Precision: 0.67\n",
      "Weighted Recall: 0.55\n",
      "Weighted F1-score: 0.47\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.69      0.56        39\n",
      "     Class 1       1.00      0.03      0.05        40\n",
      "     Class 2       0.59      0.76      0.67        71\n",
      "\n",
      "    accuracy                           0.55       150\n",
      "   macro avg       0.69      0.49      0.42       150\n",
      "weighted avg       0.67      0.55      0.47       150\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 42}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[27  0 12]\n",
      " [14  1 25]\n",
      " [17  0 54]]\n",
      "Accuracy: 0.55\n",
      "\n",
      "Micro Precision: 0.55\n",
      "Micro Recall: 0.55\n",
      "Micro F1-score: 0.55\n",
      "\n",
      "Macro Precision: 0.69\n",
      "Macro Recall: 0.49\n",
      "Macro F1-score: 0.42\n",
      "\n",
      "Weighted Precision: 0.67\n",
      "Weighted Recall: 0.55\n",
      "Weighted F1-score: 0.47\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.69      0.56        39\n",
      "     Class 1       1.00      0.03      0.05        40\n",
      "     Class 2       0.59      0.76      0.67        71\n",
      "\n",
      "    accuracy                           0.55       150\n",
      "   macro avg       0.69      0.49      0.42       150\n",
      "weighted avg       0.67      0.55      0.47       150\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 60}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[27  0 12]\n",
      " [14  1 25]\n",
      " [17  0 54]]\n",
      "Accuracy: 0.55\n",
      "\n",
      "Micro Precision: 0.55\n",
      "Micro Recall: 0.55\n",
      "Micro F1-score: 0.55\n",
      "\n",
      "Macro Precision: 0.69\n",
      "Macro Recall: 0.49\n",
      "Macro F1-score: 0.42\n",
      "\n",
      "Weighted Precision: 0.67\n",
      "Weighted Recall: 0.55\n",
      "Weighted F1-score: 0.47\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.69      0.56        39\n",
      "     Class 1       1.00      0.03      0.05        40\n",
      "     Class 2       0.59      0.76      0.67        71\n",
      "\n",
      "    accuracy                           0.55       150\n",
      "   macro avg       0.69      0.49      0.42       150\n",
      "weighted avg       0.67      0.55      0.47       150\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best Parameters\n",
      "\n",
      "{'ml__colsample_bytree': 0.99, 'ml__max_depth': 40, 'ml__min_child_samples': 20, 'ml__min_child_weight': 1e-05, 'ml__n_estimators': 5, 'ml__num_leaves': 3, 'ml__random_state': 90}\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[27  0 12]\n",
      " [14  1 25]\n",
      " [17  0 54]]\n",
      "Accuracy: 0.55\n",
      "\n",
      "Micro Precision: 0.55\n",
      "Micro Recall: 0.55\n",
      "Micro F1-score: 0.55\n",
      "\n",
      "Macro Precision: 0.69\n",
      "Macro Recall: 0.49\n",
      "Macro F1-score: 0.42\n",
      "\n",
      "Weighted Precision: 0.67\n",
      "Weighted Recall: 0.55\n",
      "Weighted F1-score: 0.47\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.69      0.56        39\n",
      "     Class 1       1.00      0.03      0.05        40\n",
      "     Class 2       0.59      0.76      0.67        71\n",
      "\n",
      "    accuracy                           0.55       150\n",
      "   macro avg       0.69      0.49      0.42       150\n",
      "weighted avg       0.67      0.55      0.47       150\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Averaged Accuracy score: 0.58%, std: 0.03%, # of Lags: 7\n",
      "---------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#creation of LGB model\n",
    "LGGclass =  LGB.LGBMClassifier()\n",
    "\n",
    "lgb7, score_lgb7, cm_lgb7, lags_lgb7 = MLpipe_RS_lgb(X7_lagged, y7_lagged, LGGclass, 2,  preprocessor_7,'f1_micro','f1_micro',7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "336a1297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6066666666666667, 0.6066666666666667, 0.6066666666666667, 0.6066666666666667, 0.6066666666666667, 0.5466666666666666, 0.5466666666666666, 0.5466666666666666, 0.5466666666666666, 0.5466666666666666]\n"
     ]
    }
   ],
   "source": [
    "print(score_lgb7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4182a89",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eed25d27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[34  0 25]\n",
      " [10  2 18]\n",
      " [ 6  0 55]]\n",
      "\n",
      "Accuracy: 0.61\n",
      "\n",
      "Micro Precision: 0.61\n",
      "Micro Recall: 0.61\n",
      "Micro F1-score: 0.61\n",
      "\n",
      "Macro Precision: 0.75\n",
      "Macro Recall: 0.51\n",
      "Macro F1-score: 0.48\n",
      "\n",
      "Weighted Precision: 0.70\n",
      "Weighted Recall: 0.61\n",
      "Weighted F1-score: 0.55\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.68      0.58      0.62        59\n",
      "     Class 2       1.00      0.07      0.12        30\n",
      "     Class 3       0.56      0.90      0.69        61\n",
      "\n",
      "    accuracy                           0.61       150\n",
      "   macro avg       0.75      0.51      0.48       150\n",
      "weighted avg       0.70      0.61      0.55       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#recreates best model prediciton using best parameters \n",
    "tscv = TimeSeriesSplit(2)\n",
    "best_modellgb7 = []\n",
    "best_scorelgb7 = []\n",
    "cmlgb7 = []\n",
    "feature_nameslgb7 = []\n",
    "\n",
    "param_grid = {'ml__colsample_bytree': [0.99], \n",
    " 'ml__max_depth': [40], \n",
    " 'ml__min_child_samples':[20],\n",
    " 'ml__min_child_weight': [1e-05], \n",
    " 'ml__n_estimators': [5],\n",
    " 'ml__num_leaves': [3],\n",
    " 'ml__random_state': [60]}\n",
    "\n",
    "X =X7_lagged\n",
    "y = y7_lagged\n",
    "\n",
    "#stops model from computing second split\n",
    "counter = 0\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    if counter == 1:\n",
    "        break\n",
    "        \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor_7), ('ml', LGGclass)])\n",
    "    gsearch = GridSearchCV(pipe, cv=tscv, param_grid= param_grid, scoring = 'f1_micro', refit = 'f1_micro')\n",
    "    gsearch.fit(X_train, y_train) \n",
    "\n",
    "    best_model = gsearch.best_estimator_\n",
    "    best_score = gsearch.best_score_\n",
    "    best_param = gsearch.best_params_\n",
    "    feature_nameslgb7 = best_model[:-1].get_feature_names_out()\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_score = accuracy_score(y_test,y_pred)\n",
    "    best_scorelgb7.append(test_score)\n",
    "    cmlgb7.append(confusion_matrix(y_test,y_pred))\n",
    "    best_modellgb7.append(best_model)\n",
    "    \n",
    "    print('\\nConfusion Matrix\\n')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "    print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "    print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "    print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "    print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "    print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "    print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "    print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "    print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "    print('\\nClassification Report\\n')\n",
    "    print(classification_report(y_test, y_pred, target_names=['Class 1', 'Class 2', 'Class 3']))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b687360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_modellgb7[0][1], open('../results/best_model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
